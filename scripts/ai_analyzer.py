#!/usr/bin/env python3
"""
AI Scene Analyzer v2.0
æ”¯æŒä¸¤ç§è¯„åˆ†æ¨¡å¼ï¼š
  - API æ¨¡å¼ï¼šé€šè¿‡ OpenAI å…¼å®¹ API è°ƒç”¨ Gemini/Kimi ç­‰è§†è§‰å¤§æ¨¡å‹
  - Agent æ¨¡å¼ï¼šç”±å®¿ä¸» AI åŠ©æ‰‹ï¼ˆIDE/OpenClaw ä¸­çš„å¤šæ¨¡æ€æ¨¡å‹ï¼‰ç›´æ¥çœ‹å›¾è¯„åˆ†

ç¯å¢ƒå˜é‡ï¼ˆAPI æ¨¡å¼ï¼‰ï¼š
  VIDEO_ANALYZER_API_KEY   - API å¯†é’¥
  VIDEO_ANALYZER_BASE_URL  - API ç«¯ç‚¹ (é»˜è®¤ https://generativelanguage.googleapis.com/v1beta/openai)
  VIDEO_ANALYZER_MODEL     - æ¨¡å‹åç§° (é»˜è®¤ gemini-2.0-flash)
"""

import json
import base64
import os
import re
import shutil
import sys
import time
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime


# ============================================================
# æœ¯è¯­å¯¹ç…§è¡¨
# ============================================================
TERMINOLOGY = {
    "TYPE-A Hook": "TYPE-A Hook (é’©å­/å¼€åœºå‹)",
    "TYPE-B Narrative": "TYPE-B Narrative (å™äº‹/æƒ…æ„Ÿå‹)",
    "TYPE-C Aesthetic": "TYPE-C Aesthetic (æ°›å›´/ç©ºé•œå‹)",
    "TYPE-D Commercial": "TYPE-D Commercial (å•†ä¸š/å±•ç¤ºå‹)",
    "aesthetic_beauty": "ç¾æ„Ÿ Aesthetic Beauty (æ„å›¾/å…‰å½±/è‰²å½©)",
    "credibility": "å¯ä¿¡åº¦ Credibility (çœŸå®æ„Ÿ/è¡¨æ¼”è‡ªç„¶åº¦)",
    "impact": "å†²å‡»åŠ› Impact (è§†è§‰æ˜¾è‘—æ€§/åŠ¨æ€å¼ åŠ›)",
    "memorability": "è®°å¿†åº¦ Memorability (ç‹¬ç‰¹ç¬¦å·/é‡‘å¥)",
    "fun_interest": "è¶£å‘³åº¦ Fun/Interest (å‚ä¸æ„Ÿ/å¨±ä¹ä»·å€¼)",
    "MUST KEEP": "MUST KEEP (å¼ºçƒˆæ¨èä¿ç•™)",
    "USABLE": "USABLE (å¯ç”¨ç´ æ)",
    "DISCARD": "DISCARD (å»ºè®®èˆå¼ƒ)",
}


def get_term_chinese(term: str) -> str:
    return TERMINOLOGY.get(term, term)


# ============================================================
# System Prompt for Vision LLM
# ============================================================
SCORING_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è§†é¢‘å‰ªè¾‘/é•œå¤´åˆ†æä¸“å®¶ï¼Œç²¾é€š Walter Murch å‰ªè¾‘å…­æ³•åˆ™ã€‚

ä½ éœ€è¦åˆ†æä¸€å¼ è§†é¢‘æˆªå¸§ï¼ŒæŒ‰ä»¥ä¸‹ç»´åº¦æ‰“åˆ†ï¼ˆ1-10 æ•´æ•°ï¼‰ï¼š

1. **aesthetic_beauty** (ç¾æ„Ÿ): æ„å›¾ï¼ˆå¦‚ä¸‰åˆ†æ³•/å¯¹ç§°ï¼‰ã€å…‰å½±è´¨æ„Ÿã€è‰²å½©å’Œè°åº¦
2. **credibility** (å¯ä¿¡åº¦): ç”»é¢çœŸå®æ„Ÿã€ç‰©ç†é€»è¾‘ã€AIç”Ÿæˆç—•è¿¹ç¨‹åº¦ï¼ˆç—•è¿¹è¶Šå°‘åˆ†è¶Šé«˜ï¼‰
3. **impact** (å†²å‡»åŠ›): ç¬¬ä¸€çœ¼è§†è§‰æ˜¾è‘—æ€§ã€åŠ¨æ€å¼ åŠ›ã€èƒ½å¦ç¬é—´å¸å¼•è§‚ä¼—
4. **memorability** (è®°å¿†åº¦): ç‹¬ç‰¹è§†è§‰ç¬¦å·ã€å†¯Â·é›·æ–¯æ‰˜å¤«æ•ˆåº”ã€è¿‡ç›®ä¸å¿˜ç¨‹åº¦
5. **fun_interest** (è¶£å‘³åº¦): å‚ä¸æ„Ÿã€å¨±ä¹ä»·å€¼ã€ç¤¾äº¤è´§å¸æ½œåŠ›

åŒæ—¶åˆ¤æ–­åœºæ™¯ç±»å‹ï¼š
- TYPE-A Hook: é«˜å†²å‡»åŠ›å¼€åœº/é«˜èƒ½ç‰‡æ®µ
- TYPE-B Narrative: å™äº‹/æƒ…æ„Ÿè¡¨è¾¾
- TYPE-C Aesthetic: ç©ºé•œ/æ°›å›´/çº¯ç¾å­¦
- TYPE-D Commercial: äº§å“å±•ç¤º/å•†ä¸šå¹¿å‘Š

ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ä»¥ä¸‹ JSON æ ¼å¼è¿”å›ç»“æœï¼Œä¸è¦é™„åŠ ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
```json
{
  "type_classification": "TYPE-X ...",
  "description": "ä¸€å¥è¯ä¸­æ–‡æè¿°ç”»é¢å†…å®¹",
  "visual_summary": "è§†è§‰å…ƒç´ æ¦‚è¦",
  "scores": {
    "aesthetic_beauty": 8,
    "credibility": 7,
    "impact": 9,
    "memorability": 8,
    "fun_interest": 7
  },
  "selection_reasoning": "å…¥é€‰/æ·˜æ±°ç†ç”±ï¼ˆä¸­æ–‡ï¼‰",
  "edit_suggestion": "å‰ªè¾‘å»ºè®®ï¼ˆä¸­æ–‡ï¼‰"
}
```"""


SCORING_USER_PROMPT_TEMPLATE = """è¯·åˆ†æä»¥ä¸‹è§†é¢‘çš„ç¬¬ {scene_num} ä¸ªåœºæ™¯æˆªå¸§ã€‚

è§†é¢‘æ ‡é¢˜ï¼š{video_title}
è§†é¢‘æ€»åœºæ™¯æ•°ï¼š{total_scenes}
{transcript_info}

è¯·ä¸¥æ ¼æŒ‰ JSON æ ¼å¼è¿”å›åˆ†æç»“æœã€‚"""


# ============================================================
# API æ¨¡å¼ï¼šè°ƒç”¨è¿œç¨‹è§†è§‰å¤§æ¨¡å‹
# ============================================================
def call_vision_api(
    frame_path: Path,
    scene_num: int,
    video_title: str = "",
    total_scenes: int = 0,
    transcript_text: str = "",
    api_key: str = "",
    base_url: str = "",
    model: str = "",
) -> Optional[Dict]:
    """é€šè¿‡ OpenAI å…¼å®¹ API è°ƒç”¨è§†è§‰å¤§æ¨¡å‹åˆ†æå¸§ç”»é¢"""

    try:
        from openai import OpenAI
    except ImportError:
        print("   âš ï¸  éœ€è¦å®‰è£… openai åº“: pip install openai")
        return None

    if not api_key:
        print("   âš ï¸  æœªè®¾ç½® VIDEO_ANALYZER_API_KEY ç¯å¢ƒå˜é‡")
        return None

    # è¯»å–å›¾ç‰‡å¹¶è½¬ base64
    with open(frame_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode("utf-8")

    mime_type = "image/jpeg" if frame_path.suffix.lower() in [".jpg", ".jpeg"] else "image/png"

    transcript_info = f"å¯¹åº”è½¬å½•æ–‡æœ¬ç‰‡æ®µï¼š{transcript_text}" if transcript_text else "ï¼ˆè¯¥åœºæ™¯æ— è½¬å½•æ–‡æœ¬ï¼‰"

    user_prompt = SCORING_USER_PROMPT_TEMPLATE.format(
        scene_num=scene_num,
        video_title=video_title,
        total_scenes=total_scenes,
        transcript_info=transcript_info,
    )

    client = OpenAI(api_key=api_key, base_url=base_url)

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": SCORING_SYSTEM_PROMPT},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": user_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{mime_type};base64,{image_data}",
                            },
                        },
                    ],
                },
            ],
            temperature=0.3,
            max_tokens=1024,
        )

        content = response.choices[0].message.content.strip()

        # æå– JSONï¼ˆå¯èƒ½åŒ…è£¹åœ¨ ```json ... ``` ä¸­ï¼‰
        json_match = re.search(r"\{[\s\S]*\}", content)
        if json_match:
            return json.loads(json_match.group())
        else:
            print(f"   âš ï¸  Scene {scene_num:03d}: æ— æ³•è§£ææ¨¡å‹è¿”å›çš„ JSON")
            return None

    except Exception as e:
        print(f"   âš ï¸  Scene {scene_num:03d}: API è°ƒç”¨å¤±è´¥ - {e}")
        return None


# ============================================================
# åŠ æƒè¯„åˆ†è®¡ç®—
# ============================================================
def compute_weighted_score(analysis: Dict) -> Dict:
    """æ ¹æ®åœºæ™¯ç±»å‹è®¡ç®—åŠ æƒåˆ†æ•°å¹¶ç¡®å®šç­›é€‰ç­‰çº§"""

    scores = analysis.get("scores", {})
    type_class = analysis.get("type_classification", "")

    # æ ¹æ®ç±»å‹åŠ¨æ€è°ƒæ•´æƒé‡
    if "TYPE-A" in type_class:
        weighted = (
            scores.get("impact", 5) * 0.40
            + scores.get("memorability", 5) * 0.30
            + scores.get("aesthetic_beauty", 5) * 0.20
            + scores.get("fun_interest", 5) * 0.10
        )
    elif "TYPE-B" in type_class:
        weighted = (
            scores.get("credibility", 5) * 0.40
            + scores.get("memorability", 5) * 0.30
            + scores.get("aesthetic_beauty", 5) * 0.20
            + scores.get("fun_interest", 5) * 0.10
        )
    elif "TYPE-C" in type_class:
        weighted = (
            scores.get("aesthetic_beauty", 5) * 0.50
            + scores.get("impact", 5) * 0.20
            + scores.get("memorability", 5) * 0.20
            + scores.get("credibility", 5) * 0.10
        )
    else:  # TYPE-D Commercial
        weighted = (
            scores.get("credibility", 5) * 0.40
            + scores.get("memorability", 5) * 0.40
            + scores.get("aesthetic_beauty", 5) * 0.20
        )

    analysis["weighted_score"] = round(weighted, 2)

    # ç¡®å®šç­›é€‰ç­‰çº§
    if weighted >= 8.5 or any(v == 10 for v in scores.values()):
        analysis["selection"] = "[MUST KEEP]"
    elif weighted >= 7.0:
        analysis["selection"] = "[USABLE]"
    else:
        analysis["selection"] = "[DISCARD]"

    return analysis


# ============================================================
# ä¸»æµç¨‹ï¼šè‡ªåŠ¨è¯„åˆ†
# ============================================================
def auto_score_scenes(scores_path: Path, video_analysis_dir: Path, mode: str = "api") -> Dict:
    """è‡ªåŠ¨ä¸ºæ‰€æœ‰åœºæ™¯è¯„åˆ†ã€‚mode='api' ä½¿ç”¨è¿œç¨‹APIï¼Œmode='agent' ä»…ç”Ÿæˆæ¨¡æ¿ä¾›å®¿ä¸»AIå¡«å†™"""

    with open(scores_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    scenes = data.get("scenes", [])
    frames_dir = video_analysis_dir / "frames"
    video_title = data.get("title", data.get("video_id", ""))
    total_scenes = len(scenes)

    # è¯»å–è½¬å½•æ–‡æœ¬
    transcript_text = ""
    for ext in ["_transcript.txt", ".srt"]:
        transcript_file = video_analysis_dir / f"{data.get('video_id', '')}{ext}"
        if transcript_file.exists():
            transcript_text = transcript_file.read_text(encoding="utf-8")
            break

    if mode == "agent":
        print(f"\nğŸ“‹ Agent æ¨¡å¼ï¼šå·²å‡†å¤‡ {total_scenes} ä¸ªåœºæ™¯çš„è¯„åˆ†æ¨¡æ¿")
        print(f"   å¸§å›¾ç‰‡ç›®å½•: {frames_dir}")
        print(f"   è¯·ä½¿ç”¨å®¿ä¸» AI çš„è§†è§‰èƒ½åŠ›é€å¸§æŸ¥çœ‹å¹¶å¡«å†™è¯„åˆ†")
        print(f"   è¯„åˆ†ç»“æœå†™å…¥: {scores_path}")
        return data

    # API æ¨¡å¼
    api_key = os.environ.get("VIDEO_ANALYZER_API_KEY", "")
    base_url = os.environ.get("VIDEO_ANALYZER_BASE_URL", "https://generativelanguage.googleapis.com/v1beta/openai")
    model = os.environ.get("VIDEO_ANALYZER_MODEL", "gemini-2.0-flash")

    if not api_key:
        print("\nâŒ API æ¨¡å¼éœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡ VIDEO_ANALYZER_API_KEY")
        print("   export VIDEO_ANALYZER_API_KEY=\"your-api-key\"")
        print("   export VIDEO_ANALYZER_BASE_URL=\"https://...\"  # å¯é€‰")
        print("   export VIDEO_ANALYZER_MODEL=\"gemini-2.0-flash\"  # å¯é€‰")
        sys.exit(1)

    print(f"\nğŸ¤– API æ¨¡å¼ï¼šä½¿ç”¨ {model} åˆ†æ {total_scenes} ä¸ªåœºæ™¯...")
    print(f"   API: {base_url}")

    success_count = 0
    for scene in scenes:
        scene_num = scene.get("scene_number", 0)
        frame_name = scene.get("filename", "").replace(".mp4", ".jpg")
        frame_path = frames_dir / frame_name

        if not frame_path.exists():
            # å°è¯•å…¶ä»–å‘½å
            alt_name = f"{data.get('video_id', '')}-Scene-{scene_num:03d}.jpg"
            frame_path = frames_dir / alt_name

        if not frame_path.exists():
            print(f"  Scene {scene_num:03d}: âš ï¸ æœªæ‰¾åˆ°å¸§å›¾ç‰‡ï¼Œè·³è¿‡")
            continue

        analysis = call_vision_api(
            frame_path=frame_path,
            scene_num=scene_num,
            video_title=video_title,
            total_scenes=total_scenes,
            transcript_text=transcript_text[:500] if transcript_text else "",
            api_key=api_key,
            base_url=base_url,
            model=model,
        )

        if analysis:
            analysis = compute_weighted_score(analysis)
            scene.update(analysis)
            success_count += 1
            print(f"  Scene {scene_num:03d}: {analysis['selection']} | åŠ æƒ {analysis['weighted_score']:.2f} | {analysis.get('type_classification', 'N/A')}")
        else:
            print(f"  Scene {scene_num:03d}: âŒ åˆ†æå¤±è´¥")

        # é™æµï¼šæ¯æ¬¡è¯·æ±‚é—´éš”
        time.sleep(1.0)

    # ä¿å­˜
    with open(scores_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… è¯„åˆ†å®Œæˆï¼š{success_count}/{total_scenes} ä¸ªåœºæ™¯æˆåŠŸ")
    print(f"   å·²ä¿å­˜åˆ°: {scores_path}")
    return data


# ============================================================
# ç²¾é€‰é•œå¤´ç­›é€‰ä¸å¤åˆ¶
# ============================================================
def select_and_copy_best_shots(scores_path: Path, threshold: float = 7.0) -> List[Dict]:
    """é€‰æ‹©æœ€ä½³é•œå¤´å¹¶å¤åˆ¶åˆ° best_shots ç›®å½•"""

    with open(scores_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    scenes = data.get("scenes", [])
    video_dir = scores_path.parent
    best_shots_dir = video_dir / "scenes" / "best_shots"
    best_shots_dir.mkdir(exist_ok=True)

    # æ¸…ç©ºæ—§çš„ç²¾é€‰
    for old in best_shots_dir.glob("*.mp4"):
        old.unlink()

    # ç­›é€‰
    best_shots = [
        s for s in scenes
        if s.get("weighted_score", 0) >= threshold or "MUST KEEP" in s.get("selection", "")
    ]
    best_shots.sort(key=lambda x: x.get("weighted_score", 0), reverse=True)

    print(f"\nâ­ å‘ç° {len(best_shots)} ä¸ªç²¾é€‰é•œå¤´ (é˜ˆå€¼: {threshold})")

    copied = []
    for i, scene in enumerate(best_shots, 1):
        src_path = Path(scene.get("file_path", ""))
        if src_path.exists():
            tag = scene.get("selection", "").replace("[", "").replace("]", "").replace(" ", "_")
            dst_name = f"{i:02d}_{tag}_{src_path.name}"
            dst_path = best_shots_dir / dst_name
            shutil.copy2(src_path, dst_path)
            copied.append(scene)
            desc = scene.get("description", "N/A")[:30]
            print(f"  {i}. Scene {scene.get('scene_number', 0):03d} | {scene.get('weighted_score', 0):.2f} | {desc}...")

    # ç”Ÿæˆ README
    _generate_readme(best_shots_dir, copied, data.get("video_id", "unknown"))

    print(f"\nâœ… å·²å¤åˆ¶ {len(copied)} ä¸ªç²¾é€‰é•œå¤´åˆ°: {best_shots_dir}")
    return copied


def _generate_readme(best_shots_dir: Path, best_shots: List[Dict], video_id: str):
    content = f"""# â­ ç²¾é€‰é•œå¤´ (Best Shots)

**è§†é¢‘ ID**: {video_id}
**å…¥é€‰æ•°é‡**: {len(best_shots)} ä¸ª
**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ç²¾é€‰åˆ—è¡¨

| æ’å | åœºæ™¯ | åŠ æƒåˆ† | ç±»å‹ | æè¿° |
|------|------|--------|------|------|
"""
    for i, s in enumerate(best_shots, 1):
        content += f"| {i} | Scene {s.get('scene_number', 0):03d} | {s.get('weighted_score', 0):.2f} | {s.get('type_classification', 'N/A')} | {s.get('description', '')[:40]} |\n"

    content += f"\n---\n*ç”± Video Expert Analyzer v2.0 ç­›é€‰*\n"

    (best_shots_dir / "README.md").write_text(content, encoding="utf-8")


# ============================================================
# åˆ†ææŠ¥å‘Šç”Ÿæˆ
# ============================================================
def generate_complete_report(scores_path: Path) -> Path:
    with open(scores_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    video_id = data.get("video_id", "unknown")
    url = data.get("url", "")
    scenes = data.get("scenes", [])
    total = len(scenes)

    if total == 0:
        print("âš ï¸ æ²¡æœ‰åœºæ™¯æ•°æ®")
        return scores_path

    # ç»Ÿè®¡
    scored_scenes = [s for s in scenes if "weighted_score" in s]
    if not scored_scenes:
        print("âš ï¸ æ²¡æœ‰å·²è¯„åˆ†çš„åœºæ™¯")
        return scores_path

    must_keep = sum(1 for s in scored_scenes if "MUST KEEP" in s.get("selection", ""))
    usable = sum(1 for s in scored_scenes if "USABLE" in s.get("selection", ""))
    discard = sum(1 for s in scored_scenes if "DISCARD" in s.get("selection", ""))
    avg = sum(s["weighted_score"] for s in scored_scenes) / len(scored_scenes)

    # å„ç»´åº¦å¹³å‡
    dims = ["aesthetic_beauty", "credibility", "impact", "memorability", "fun_interest"]
    dim_avgs = {}
    for d in dims:
        vals = [s.get("scores", {}).get(d, 0) for s in scored_scenes if s.get("scores", {}).get(d)]
        dim_avgs[d] = sum(vals) / len(vals) if vals else 0

    report_path = scores_path.parent / f"{video_id}_complete_analysis.md"

    sorted_scenes = sorted(scored_scenes, key=lambda x: x.get("weighted_score", 0), reverse=True)

    # æ„å»ºæŠ¥å‘Š
    report = f"""# ğŸ¬ è§†é¢‘ä¸“å®¶åˆ†ææŠ¥å‘Š (Video Expert Analysis Report)

## ğŸ“‹ åŸºæœ¬ä¿¡æ¯

| é¡¹ç›® | å†…å®¹ |
|------|------|
| **è§†é¢‘ ID** | {video_id} |
| **æ¥æº URL** | {url} |
| **åˆ†ææ—¶é—´** | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} |
| **æ€»åœºæ™¯æ•°** | {total} |
| **å·²è¯„åˆ†** | {len(scored_scenes)} |
| **å¹³å‡åŠ æƒå¾—åˆ†** | {avg:.2f} |

### ç­›é€‰ç»Ÿè®¡

| ç­‰çº§ | æ•°é‡ | å æ¯” |
|------|------|------|
| ğŸŒŸ MUST KEEP | {must_keep} | {must_keep/len(scored_scenes)*100:.1f}% |
| ğŸ“ USABLE | {usable} | {usable/len(scored_scenes)*100:.1f}% |
| ğŸ—‘ï¸ DISCARD | {discard} | {discard/len(scored_scenes)*100:.1f}% |

### å„ç»´åº¦å¹³å‡åˆ†

| ç»´åº¦ | å¹³å‡åˆ† |
|------|--------|
"""
    for d in dims:
        icon = "ğŸŸ¢" if dim_avgs[d] >= 7 else "ğŸŸ¡" if dim_avgs[d] >= 5 else "ğŸ”´"
        report += f"| {get_term_chinese(d)} | {dim_avgs[d]:.2f} {icon} |\n"

    report += f"""
---

## ğŸ åœºæ™¯æ’å

| æ’å | åœºæ™¯ | åŠ æƒåˆ† | ç±»å‹ | ç­‰çº§ | æè¿° |
|------|------|--------|------|------|------|
"""
    for i, s in enumerate(sorted_scenes, 1):
        desc = s.get("description", "N/A")[:30]
        report += f"| {i} | Scene {s.get('scene_number', 0):03d} | **{s.get('weighted_score', 0):.2f}** | {s.get('type_classification', 'N/A')} | {s.get('selection', '')} | {desc} |\n"

    report += f"""
---

## ğŸ“Š æ•´ä½“è¯„ä»·

### ç»¼åˆè¯„åˆ†: {avg:.2f} / 10

"""
    if avg >= 8:
        report += "ğŸŒŸ **ä¼˜ç§€** - é«˜è´¨é‡ç´ æï¼Œå¼ºçƒˆæ¨èä¿ç•™\n"
    elif avg >= 6.5:
        report += "ğŸ“ **è‰¯å¥½** - æœ‰å¯ç”¨ä»·å€¼ï¼Œéœ€è¦é€‚å½“å‰ªè¾‘\n"
    else:
        report += "ğŸ—‘ï¸ **ä¸€èˆ¬** - æ•´ä½“è´¨é‡è¾ƒä½\n"

    report += f"""
---
*æœ¬æŠ¥å‘Šç”± Video Expert Analyzer v2.0 è‡ªåŠ¨ç”Ÿæˆ*
*åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""

    report_path.write_text(report, encoding="utf-8")
    print(f"âœ… å®Œæ•´åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    return report_path


# ============================================================
# CLI å…¥å£
# ============================================================
if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("""ç”¨æ³•: python3 ai_analyzer.py <scene_scores.json> [--mode api|agent]

è¯„åˆ†æ¨¡å¼:
  --mode api    é€šè¿‡è¿œç¨‹ API è°ƒç”¨è§†è§‰å¤§æ¨¡å‹è¯„åˆ†ï¼ˆéœ€è®¾ç½® VIDEO_ANALYZER_API_KEYï¼‰
  --mode agent  ç”Ÿæˆè¯„åˆ†æ¨¡æ¿ï¼Œç”±å®¿ä¸» AI åŠ©æ‰‹ï¼ˆå¦‚ IDE ä¸­çš„ Gemini/Kimiï¼‰ç›´æ¥çœ‹å›¾è¯„åˆ†

ç¯å¢ƒå˜é‡ (API æ¨¡å¼):
  VIDEO_ANALYZER_API_KEY    API å¯†é’¥ï¼ˆå¿…éœ€ï¼‰
  VIDEO_ANALYZER_BASE_URL   API ç«¯ç‚¹ï¼ˆé»˜è®¤ Geminiï¼‰
  VIDEO_ANALYZER_MODEL      æ¨¡å‹åç§°ï¼ˆé»˜è®¤ gemini-2.0-flashï¼‰
""")
        sys.exit(1)

    scores_path = Path(sys.argv[1])
    video_dir = scores_path.parent

    # è§£ææ¨¡å¼
    mode = "api"
    if "--mode" in sys.argv:
        idx = sys.argv.index("--mode")
        if idx + 1 < len(sys.argv):
            mode = sys.argv[idx + 1]

    print("=" * 60)
    print(f"ğŸ¤– AI Scene Analyzer v2.0 ({mode.upper()} æ¨¡å¼)")
    print("=" * 60)

    # 1. è‡ªåŠ¨è¯„åˆ†
    data = auto_score_scenes(scores_path, video_dir, mode=mode)

    if mode == "agent":
        print("\n" + "=" * 60)
        print("ğŸ“ Agent æ¨¡å¼è¯´æ˜")
        print("=" * 60)
        print(f"\nè¯·ä½¿ç”¨å®¿ä¸» AI åŠ©æ‰‹çš„è§†è§‰èƒ½åŠ›å®Œæˆä»¥ä¸‹æ­¥éª¤ï¼š")
        print(f"  1. æŸ¥çœ‹ {video_dir}/frames/ ä¸­çš„æ¯å¼ æˆªå¸§")
        print(f"  2. æŒ‰ Walter Murch æ³•åˆ™äº”ç»´åº¦æ‰“åˆ†")
        print(f"  3. å°†ç»“æœæ›´æ–°åˆ° {scores_path}")
        print(f"  4. å†æ¬¡è¿è¡Œæœ¬è„šæœ¬ï¼ˆä¸å¸¦ --mode agentï¼‰ç”ŸæˆæŠ¥å‘Š")
        sys.exit(0)

    # 2. å¤åˆ¶ç²¾é€‰é•œå¤´
    print("\n" + "=" * 60)
    print("â­ é€‰æ‹©å¹¶å¤åˆ¶ç²¾é€‰é•œå¤´")
    print("=" * 60)
    select_and_copy_best_shots(scores_path, threshold=7.0)

    # 3. ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“„ ç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Š")
    print("=" * 60)
    report_path = generate_complete_report(scores_path)

    print("\n" + "=" * 60)
    print("âœ… AI åˆ†æå®Œæˆ!")
    print("=" * 60)
    print(f"\nğŸ“Š è¯„åˆ†æ–‡ä»¶: {scores_path}")
    print(f"â­ ç²¾é€‰é•œå¤´: {video_dir}/scenes/best_shots/")
    print(f"ğŸ“„ å®Œæ•´æŠ¥å‘Š: {report_path}")
